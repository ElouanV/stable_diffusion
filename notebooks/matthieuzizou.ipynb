{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-11-30T16:15:29.324359526Z",
     "start_time": "2023-11-30T16:15:27.499397683Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('../')\n",
    "from src import dataset\n",
    "import numpy as np\n",
    "from src.model_bis import Unet\n",
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "T = 100"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-30T16:15:29.324657516Z",
     "start_time": "2023-11-30T16:15:29.312769131Z"
    }
   },
   "id": "5509ab952f0c125c"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "alphas = 1. - torch.linspace(0.001, 0.2, T)\n",
    "alphas_cumprod = torch.cumprod(alphas, axis=0)\n",
    "\n",
    "sqrt_alphas_cumprod = torch.sqrt(alphas_cumprod)\n",
    "sqrt_one_minus_alphas_cumprod = torch.sqrt(1 - sqrt_alphas_cumprod ** 2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-30T16:15:29.324795756Z",
     "start_time": "2023-11-30T16:15:29.320499372Z"
    }
   },
   "id": "55031ac564a9e1c7"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def extract(a, t, x_shape):\n",
    "    batch_size = t.shape[0]\n",
    "    out = a.gather(-1, t.cpu())\n",
    "    return out.reshape(batch_size, *((1,) * (len(x_shape) - 1))).to(t.device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-30T16:15:29.354744623Z",
     "start_time": "2023-11-30T16:15:29.329905126Z"
    }
   },
   "id": "238103845c873d3d"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# forward diffusion\n",
    "def q_sample(x_0, t, noise=None):\n",
    "    if noise is None:\n",
    "        noise = torch.randn_like(x_0)\n",
    "\n",
    "    sqrt_alphas_cumprod_t = extract(sqrt_alphas_cumprod, t, x_0.shape)\n",
    "    sqrt_one_minus_alphas_cumprod_t = extract(\n",
    "        sqrt_one_minus_alphas_cumprod, t, x_0.shape\n",
    "    )\n",
    "\n",
    "    return sqrt_alphas_cumprod_t * x_0 + sqrt_one_minus_alphas_cumprod_t * noise"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-30T16:15:29.387094362Z",
     "start_time": "2023-11-30T16:15:29.342916575Z"
    }
   },
   "id": "47999b8d44e0af42"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def p_losses(denoise_model, x_start, t, noise=None):\n",
    "    if noise is None:\n",
    "        noise = torch.randn_like(x_start)\n",
    "    x_noisy = q_sample(x_0=x_start, t=t, noise=noise)\n",
    "    predicted_noise = denoise_model(x_noisy, t)\n",
    "    loss = F.mse_loss(noise, predicted_noise)\n",
    "    return loss"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-30T16:15:29.387319745Z",
     "start_time": "2023-11-30T16:15:29.387005790Z"
    }
   },
   "id": "3128754ccbc2b84c"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "from torchvision.transforms import Compose"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-30T16:15:29.387908784Z",
     "start_time": "2023-11-30T16:15:29.387196761Z"
    }
   },
   "id": "bb7a26363ca83192"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "Downloading builder script:   0%|          | 0.00/3.98k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b3b55c49de1c4356bc6eadb467f744a8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading metadata:   0%|          | 0.00/2.21k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e26cc32044d14e97a55fb75af7c270f8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading readme:   0%|          | 0.00/6.83k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4c7767a23c624faa8648742c5f48aa11"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading data files:   0%|          | 0/4 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3b5221478343472b9cb1e3bc3916988f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading data:   0%|          | 0.00/9.91M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6d55f6d446f54246b8e93257dc9e6e42"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading data:   0%|          | 0.00/28.9k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2bae956bb1c7477db5c52b32e41e4b16"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading data:   0%|          | 0.00/1.65M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a1bc2b0d701045cf8c776199ebad2657"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading data:   0%|          | 0.00/4.54k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "543a0484303b4d7b9ce7a52973a5c88a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Extracting data files:   0%|          | 0/4 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5febf80bb0544b92bea793d5cf5a16a4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Generating train split:   0%|          | 0/60000 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5ff592fc9b1b4218a3da7248c3182c29"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Generating test split:   0%|          | 0/10000 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ceb25d85e57044d98dab4846eb32d31a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# load dataset from the hub\n",
    "dataset = load_dataset(\"mnist\")\n",
    "image_size = 28\n",
    "channels = 1\n",
    "batch_size = 128"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-30T18:27:55.461191277Z",
     "start_time": "2023-11-30T18:27:42.034033040Z"
    }
   },
   "id": "6479a78458757bff"
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model = Unet(\n",
    "    dim=image_size,\n",
    "    channels=channels,\n",
    "    dim_mults=(1, 2, 4,)\n",
    ")\n",
    "model.to(device)\n",
    "\n",
    "optimizer = Adam(model.parameters(), lr=1e-3)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-30T18:30:42.663272494Z",
     "start_time": "2023-11-30T18:30:42.615293210Z"
    }
   },
   "id": "203855f1ea25c8ed"
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# define image transformations (e.g. using torchvision)\n",
    "transform = Compose([\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Lambda(lambda t: (t * 2) - 1)\n",
    "])\n",
    "\n",
    "# define function\n",
    "def transforms(examples):\n",
    "   examples[\"pixel_values\"] = [transform(image.convert(\"L\")) for image in examples[\"image\"]]\n",
    "   del examples[\"image\"]\n",
    "\n",
    "   return examples\n",
    "\n",
    "transformed_dataset = dataset.with_transform(transforms).remove_columns(\"label\")\n",
    "\n",
    "# create dataloader\n",
    "dataloader = DataLoader(transformed_dataset[\"train\"], batch_size=batch_size, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-30T18:30:43.201482786Z",
     "start_time": "2023-11-30T18:30:43.186684335Z"
    }
   },
   "id": "afd6ea399c55ddc3"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-30T18:30:43.661870063Z",
     "start_time": "2023-11-30T18:30:43.658102081Z"
    }
   },
   "id": "14fbcaed05669043"
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "def cosine_beta_schedule(timesteps, s=0.008):\n",
    "    \"\"\"\n",
    "    cosine schedule as proposed in https://arxiv.org/abs/2102.09672\n",
    "    \"\"\"\n",
    "    steps = timesteps + 1\n",
    "    x = torch.linspace(0, timesteps, steps)\n",
    "    alphas_cumprod = torch.cos(((x / timesteps) + s) / (1 + s) * torch.pi * 0.5) ** 2\n",
    "    alphas_cumprod = alphas_cumprod / alphas_cumprod[0]\n",
    "    betas = 1 - (alphas_cumprod[1:] / alphas_cumprod[:-1])\n",
    "    return torch.clip(betas, 0.0001, 0.9999)\n",
    "\n",
    "def linear_beta_schedule(timesteps):\n",
    "    beta_start = 0.0001\n",
    "    beta_end = 0.02\n",
    "    return torch.linspace(beta_start, beta_end, timesteps)\n",
    "\n",
    "def quadratic_beta_schedule(timesteps):\n",
    "    beta_start = 0.0001\n",
    "    beta_end = 0.02\n",
    "    return torch.linspace(beta_start**0.5, beta_end**0.5, timesteps) ** 2\n",
    "\n",
    "def sigmoid_beta_schedule(timesteps):\n",
    "    beta_start = 0.0001\n",
    "    beta_end = 0.02\n",
    "    betas = torch.linspace(-6, 6, timesteps)\n",
    "    return torch.sigmoid(betas) * (beta_end - beta_start) + beta_start"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-30T18:30:44.163298312Z",
     "start_time": "2023-11-30T18:30:44.158933217Z"
    }
   },
   "id": "42077f19ecd95c31"
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "# define beta schedule\n",
    "betas = linear_beta_schedule(timesteps=T)\n",
    "\n",
    "# define alphas \n",
    "alphas = 1. - betas\n",
    "alphas_cumprod = torch.cumprod(alphas, axis=0)\n",
    "alphas_cumprod_prev = F.pad(alphas_cumprod[:-1], (1, 0), value=1.0)\n",
    "sqrt_recip_alphas = torch.sqrt(1.0 / alphas)\n",
    "\n",
    "# calculations for diffusion q(x_t | x_{t-1}) and others\n",
    "sqrt_alphas_cumprod = torch.sqrt(alphas_cumprod)\n",
    "sqrt_one_minus_alphas_cumprod = torch.sqrt(1. - alphas_cumprod)\n",
    "\n",
    "# calculations for posterior q(x_{t-1} | x_t, x_0)\n",
    "posterior_variance = betas * (1. - alphas_cumprod_prev) / (1. - alphas_cumprod)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-30T18:30:44.649394832Z",
     "start_time": "2023-11-30T18:30:44.641739566Z"
    }
   },
   "id": "9965663caaae8e44"
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def p_sample(model, x, t, t_index):\n",
    "    betas_t = extract(betas, t, x.shape)\n",
    "    sqrt_one_minus_alphas_cumprod_t = extract(\n",
    "        sqrt_one_minus_alphas_cumprod, t, x.shape\n",
    "    )\n",
    "    sqrt_recip_alphas_t = extract(sqrt_recip_alphas, t, x.shape)\n",
    "    \n",
    "    # Equation 11 in the paper\n",
    "    # Use our model (noise predictor) to predict the mean\n",
    "    model_mean = sqrt_recip_alphas_t * (\n",
    "        x - betas_t * model(x, t) / sqrt_one_minus_alphas_cumprod_t\n",
    "    )\n",
    "\n",
    "    if t_index == 0:\n",
    "        return model_mean\n",
    "    else:\n",
    "        posterior_variance_t = extract(posterior_variance, t, x.shape)\n",
    "        noise = torch.randn_like(x)\n",
    "        # Algorithm 2 line 4:\n",
    "        return model_mean + torch.sqrt(posterior_variance_t) * noise \n",
    "\n",
    "# Algorithm 2 but save all images:\n",
    "@torch.no_grad()\n",
    "def p_sample_loop(model, shape):\n",
    "    device = next(model.parameters()).device\n",
    "\n",
    "    b = shape[0]\n",
    "    # start from pure noise (for each example in the batch)\n",
    "    img = torch.randn(shape, device=device)\n",
    "    imgs = []\n",
    "    \n",
    "    for i in tqdm(reversed(range(0, T)), desc='sampling loop time step', total=T):\n",
    "        img = p_sample(model, img, torch.full((b,), i, device=device, dtype=torch.long), i)\n",
    "        imgs.append(img.cpu().numpy())\n",
    "    return imgs\n",
    "\n",
    "@torch.no_grad()\n",
    "def sample(model, image_size, batch_size=16, channels=3):\n",
    "    return p_sample_loop(model, shape=(batch_size, channels, image_size, image_size))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-30T18:30:45.186093022Z",
     "start_time": "2023-11-30T18:30:45.183556506Z"
    }
   },
   "id": "70175257ddd1a334"
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "def num_to_groups(num, divisor):\n",
    "    groups = num // divisor\n",
    "    remainder = num % divisor\n",
    "    arr = [divisor] * groups\n",
    "    if remainder > 0:\n",
    "        arr.append(remainder)\n",
    "    return arr\n",
    "\n",
    "results_folder = Path(\"./results\")\n",
    "results_folder.mkdir(exist_ok = True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-30T18:30:45.823197075Z",
     "start_time": "2023-11-30T18:30:45.799876036Z"
    }
   },
   "id": "217f4c1e36d9ba37"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/469 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.294183373451233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██▏       | 100/469 [03:13<11:37,  1.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.32803967595100403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 200/469 [06:25<08:26,  1.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.16988053917884827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 300/469 [09:37<05:29,  1.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.11812780052423477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 400/469 [12:50<02:10,  1.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.09504061192274094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 450/469 [14:28<00:35,  1.87s/it]"
     ]
    }
   ],
   "source": [
    "from torchvision.utils import save_image\n",
    "from tqdm import tqdm\n",
    "epochs = 5\n",
    "save_and_sample_every = 1000    \n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch {epoch+1}\\n-------------------------------\")\n",
    "    for step, batch in enumerate(tqdm(dataloader)):\n",
    "      optimizer.zero_grad()\n",
    "\n",
    "      batch_size = batch[\"pixel_values\"].shape[0]\n",
    "      batch = batch[\"pixel_values\"].to(device)\n",
    "\n",
    "      # Algorithm 1 line 3: sample t uniformally for every example in the batch\n",
    "      t = torch.randint(0, T, (batch_size,), device=device).long()\n",
    "\n",
    "      loss = p_losses(model, batch, t)\n",
    "\n",
    "      if step % 100 == 0:\n",
    "        print(\"Loss:\", loss.item())\n",
    "\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "      # save generated images\n",
    "      if step != 0 and step % save_and_sample_every == 0:\n",
    "        milestone = step // save_and_sample_every\n",
    "        batches = num_to_groups(4, batch_size)\n",
    "        all_images_list = list(map(lambda n: sample(model, batch_size=n, channels=channels), batches))\n",
    "        all_images = torch.cat(all_images_list, dim=0)\n",
    "        all_images = (all_images + 1) * 0.5\n",
    "        save_image(all_images, str(results_folder / f'sample-{milestone}.png'), nrow = 6)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2023-11-30T18:30:46.295376267Z"
    }
   },
   "id": "69e9db6a08efb935"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "samples = sample(model, image_size=image_size, batch_size=64, channels=channels)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "4e3434c4211b1c96"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "64172e4453e11ff1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# show a random one\n",
    "random_index = 5\n",
    "plt.imshow(samples[-1][random_index].reshape(image_size, image_size, channels), cmap=\"gray\")"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "559d0cb09ab3ca2e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.animation as animation\n",
    "\n",
    "random_index = 53\n",
    "\n",
    "fig = plt.figure()\n",
    "ims = []\n",
    "for i in range(T):\n",
    "    im = plt.imshow(samples[i][random_index].reshape(image_size, image_size, channels), cmap=\"gray\", animated=True)\n",
    "    ims.append([im])\n",
    "\n",
    "animate = animation.ArtistAnimation(fig, ims, interval=50, blit=True, repeat_delay=1000)\n",
    "animate.save('diffusion.gif')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "5fd02278952d4479"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Save the model checkpoint\n",
    "torch.save(model.state_dict(), 'model.ckpt')\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "c2d53fa69026184f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
